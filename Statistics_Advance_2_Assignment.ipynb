{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question1: Define the z-statistic and explain its relationship to the standard normal distribution. How is the z-statistic used in hypothesis testing?**"
      ],
      "metadata": {
        "id": "xu00NiCU0Lys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The z-statistic (or z-score) is a statistical measurement that describes how many standard deviations a data point is from the mean of a distribution. It is primarily used when data follows a normal distribution, and it standardizes data by converting values into a common scale with a mean of 0 and a standard deviation of 1, which corresponds to the standard normal distribution.\n",
        "\n",
        "The z-statistic is calculated using the following formula:\n",
        "z= (X-μ)/σ\n",
        "\n",
        "X = the data point or sample mean\n",
        "\n",
        "μ = the population mean (or the expected value)\n",
        "\n",
        "σ = the population standard deviation\n",
        "\n",
        "\n",
        "Relationship to the Standard Normal Distribution:\n",
        "\n",
        "The standard normal distribution is a normal distribution with a mean of 0 and a standard deviation of 1. The z-statistic transforms any normal distribution to the standard normal distribution, which allows for easy comparison of data from different normal distributions.\n",
        "\n",
        "In the standard normal distribution:\n",
        "\n",
        "68.27% of the data falls within 1 standard deviation (z-scores between -1 and 1).\n",
        "\n",
        "95.45% falls within 2 standard deviations (z-scores between -2 and 2).\n",
        "\n",
        "99.73% falls within 3 standard deviations (z-scores between -3 and 3).\n",
        "\n",
        "By converting raw data into z-scores, you can easily reference standard normal distribution tables (z-tables) to find probabilities and make statistical inferences.\n",
        "\n",
        "Z-Statistic in Hypothesis Testing:\n",
        "\n",
        "The z-statistic is commonly used in hypothesis testing, particularly when the population standard deviation (σ) is known and the sample size is large (n > 30). The goal is to determine if a sample mean significantly differs from the population mean.\n",
        "\n",
        "Formulate the Hypotheses:\n",
        "\n",
        "1. Null Hypothesis (H₀):There is no effect or difference. For example, H₀:μ=μ₀\n",
        "where is μ₀ the population mean.\n",
        "\n",
        "2. Alternative Hypothesis (H₁): There is a significant effect or difference. For example, H₁:μ≠μ₀\n",
        "\n",
        "Calculate the Z-Statistic:\n",
        "\n",
        "For a sample mean X: z= (X-μ)/σ/√n\n",
        "\n",
        "Where:\n",
        "X= sample mean\n",
        "μ₀= hypothesized population mean\n",
        "σ = population standard deviation\n",
        "n = sample size\n",
        "\n",
        "Determine the Critical Value:\n",
        "\n",
        "Choose a significance level (α), typically 0.05 or 0.01, and determine the critical z-value from the z-table corresponding to this significance level.\n",
        "For a two-tailed test at α = 0.05, the critical z-values are approximately ±1.96 (for a 95% confidence level).\n",
        "\n",
        "Make a Decision:\n",
        "\n",
        "Compare the calculated z-statistic to the critical z-value.\n",
        "If the absolute value of the z-statistic exceeds the critical z-value, reject the null hypothesis.\n",
        "Otherwise, fail to reject the null hypothesis."
      ],
      "metadata": {
        "id": "uFvgZpaP1uOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question2 : What is a p-value, and how is it used in hypothesis testing? What does it mean if the p-value is very small (e.g., 0.01)?**"
      ],
      "metadata": {
        "id": "yTYvwzhg5Lh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The p-value is a fundamental concept in hypothesis testing. It represents the probability of observing a test statistic (or something more extreme) assuming that the null hypothesis (H₀) is true. In other words, it tells us how likely it is to get the observed data (or more extreme data) if there is no actual effect or difference.\n",
        "\n",
        "The p-value is the probability of obtaining a result at least as extreme as the one observed, under the assumption that the null hypothesis is true. Formally, it’s calculated as:\n",
        "\n",
        "p=P(test statistic ≥ observed value | H₀ is true)\n",
        "\n",
        "A large p-value suggests that the observed data is consistent with the null hypothesis.\n",
        "A small p-value suggests that the observed data is unlikely under the null hypothesis, indicating that the null hypothesis might not be true.\n",
        "\n",
        "P-Value in Hypothesis Testing:\n",
        "\n",
        "Formulating the Hypotheses:\n",
        "\n",
        "Null Hypothesis (H₀): A statement of no effect or no difference (e.g.,  H₀:μ=μ₀ )\n",
        "\n",
        "Alternative Hypothesis (H₁): A statement that contradicts the null hypothesis (e.g., H₁:μ≠μ₀)\n",
        "\n",
        "nducting the Test:\n",
        "\n",
        "Collect data and calculate a test statistic (e.g., z-statistic, t-statistic) that quantifies how far the sample data is from what is expected under the null hypothesis.\n",
        "\n",
        "Calculating the P-Value:\n",
        "\n",
        "Use the test statistic and a probability distribution (e.g., the standard normal distribution for a z-test or the t-distribution for a t-test) to determine the p-value. The p-value is the area under the curve beyond the observed test statistic (i.e., the probability of getting that result or something more extreme).\n",
        "\n",
        "Decision Rule:\n",
        "\n",
        "Compare the p-value to a predetermined significance level (α), typically 0.05 or 0.01.\n",
        "If p ≤ α, reject the null hypothesis (statistically significant result).\n",
        "If p > α, fail to reject the null hypothesis (result is not statistically significant).\n",
        "\n",
        "\n",
        "Small P-Value (e.g., 0.01):\n",
        "\n",
        "If the p-value is very small (such as 0.01), it means the observed data is highly unlikely under the null hypothesis. In other words, there's only a 1% chance that you would observe such extreme data if the null hypothesis were true.\n",
        "A small p-value leads to rejecting the null hypothesis, indicating that there is strong evidence in favor of the alternative hypothesis."
      ],
      "metadata": {
        "id": "dopozXTY5N89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question3: Compare and contrast the binomial and Bernoulli distributions.**"
      ],
      "metadata": {
        "id": "G4R1IlWm6bWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The binomial and Bernoulli distributions are both discrete probability distributions that describe the number of successes in a series of independent trials. However, they have some key differences:\n",
        "\n",
        "Bernoulli Distribution:\n",
        "\n",
        "Describes the outcome of a single binary trial (success or failure).\n",
        "Has only two possible values: 0 (failure) and 1 (success).\n",
        "The probability of success is denoted by p and the probability of failure is denoted by q = 1 - p.\n",
        "The mean of a Bernoulli distribution is p and the variance is p(1-p).\n",
        "\n",
        "Binomial Distribution:\n",
        "\n",
        "Describes the number of successes in a fixed number of independent Bernoulli trials.\n",
        "The probability\n",
        "\n",
        " of exactly k successes in n trials is given by the binomial probability mass function: P(X = k) = nCk * pk * (1-p)^(n-k) where nCk is the combination of n things taken k at a time. The mean of a binomial distribution is np and the variance is np(1-p).\n",
        "\n",
        " Comparison:\n",
        "\n",
        " A Bernoulli distribution is a special case of a binomial distribution with n = 1.\n",
        "Both distributions have the same parameters: p and q.\n",
        "The binomial distribution is used to model the number of successes in multiple trials, while the Bernoulli distribution is used to model the outcome of a single trial."
      ],
      "metadata": {
        "id": "48fPb9jX8bxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: Under what conditions is the binomial distribution used, and how does it relate to the Bernoulli distribution?**"
      ],
      "metadata": {
        "id": "BaOzSdHC9Jsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The binomial distribution is used to model the number of successes in a fixed number of independent Bernoulli trials. Each trial has only two possible outcomes (success or failure), and the probability of success (p) remains constant across all trials.\n",
        "\n",
        "Conditions for using the binomial distribution:\n",
        "\n",
        "The trials must be independent. This means that the outcome of one trial does not affect the outcome of the next trial.\n",
        "The probability of success (p) must remain constant across all trials.\n",
        "The number of trials (n) must be fixed.\n",
        "\n",
        "Relationship to the Bernoulli distribution:\n",
        "\n",
        "The Bernoulli distribution is a special case of the binomial distribution with n = 1. This means that it describes the outcome of a single binary trial. The binomial distribution can be thought of as the sum of n independent Bernoulli trials."
      ],
      "metadata": {
        "id": "E9-3h1aa9UqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question5: What are the key properties of the Poisson distribution, and when is it appropriate to use this distribution?**"
      ],
      "metadata": {
        "id": "4BeUOhsI9mOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Poisson distribution is a discrete probability distribution that describes the number of events occurring in a fixed interval of time or space. It is often used to model rare events, such as the number of car accidents on a highway, the number of customers arriving at a store, or the number of radioactive decays in a sample.\n",
        "\n",
        "Key properties of the Poisson distribution:\n",
        "\n",
        "Mean and variance are equal: The mean and variance of a Poisson distribution are both equal to the parameter λ.\n",
        "\n",
        "No upper limit: The Poisson distribution can take on any non-negative integer value.\n",
        "\n",
        "Asymptotic normality: For large values of λ, the Poisson distribution can be approximated by a normal distribution with mean λ and variance λ.\n",
        "\n",
        "When to use the Poisson distribution:\n",
        "\n",
        "The events being counted are rare (i.e., the probability of an event occurring in a small interval is small).\n",
        "The events occur independently of each other.\n",
        "The rate of occurrence of events is constant over time or space.\n",
        "\n"
      ],
      "metadata": {
        "id": "NjpM1rnO94iY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question6: Define the terms \"probability distribution\" and \"probability density function\" (PDF). How does a PDF differ from a probability mass function (PMF)?**"
      ],
      "metadata": {
        "id": "DW2bFZ6Y-YsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probability Distribution:\n",
        "\n",
        "A probability distribution is a mathematical function that describes the likelihood of different possible outcomes of a random variable. It provides a complete picture of the probability of each possible value occurring.\n",
        "\n",
        "Probability Mass Function (PMF):\n",
        "\n",
        "A PMF is used for discrete random variables. It gives the probability that a discrete random variable is exactly equal to a specific value. In other words, it assigns a probability to each possible outcome.\n",
        "\n",
        "Probability Density Function (PDF):\n",
        "\n",
        "A PDF is used for continuous random variables. It does not give the exact probability of a specific value occurring, but rather the probability density at that point. The probability of a continuous random variable falling within a certain range is calculated by integrating the PDF over that range.\n",
        "\n",
        "Key Differences:\n",
        "\n",
        "Discrete vs. Continuous: PMFs are used for discrete variables, while PDFs are used for continuous variables.\n",
        "\n",
        "Exact Probability: PMFs give the exact probability of a specific value, while PDFs give the probability density at a point.\n",
        "\n",
        "Integration: To find the probability of a continuous random variable falling within a range, you need to integrate the PDF over that range."
      ],
      "metadata": {
        "id": "GS9hdV-e-hyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question7: Explain the Central Limit Theorem (CLT) with example**"
      ],
      "metadata": {
        "id": "Ntk1Yw0d_sK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Central Limit Theorem (CLT) is a fundamental theorem in statistics that states:\n",
        "\n",
        "\"The distribution of sample means from a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the underlying distribution of the individual random variables.\"\n",
        "\n",
        "In simpler terms, no matter what the shape of the original population distribution (even if it's not normal), the distribution of sample means taken from that population will become increasingly normal as the sample size increases.\n",
        "\n",
        "Example:\n",
        "\n",
        "Suppose you have a population of heights that is not normally distributed (e.g., it is skewed to the right). If you take many random samples of a large size from this population and calculate the mean height for each sample, the distribution of these sample means will be approximately normal, even if the original population distribution is not."
      ],
      "metadata": {
        "id": "vSlyeUB3_xNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question8: Compare z-scores and t-scores. When should you use a z-score, and when should a t-score be applied instead?**"
      ],
      "metadata": {
        "id": "OFESRG_-ANsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "z-scores:\n",
        "\n",
        "Assumptions: Known population standard deviation.\n",
        "\n",
        "Usage: Used when the population standard deviation is known, or when the sample size is large (typically n ≥ 30).\n",
        "\n",
        "Calculation: z = (x - μ) / σ, where x is the data point, μ is the population mean, and σ is the population standard deviation.\n",
        "\n",
        "t-scores:\n",
        "\n",
        "Assumptions: Unknown population standard deviation, estimated using the sample standard deviation.\n",
        "\n",
        "Usage: Used when the population standard deviation is unknown, or when the sample size is small (typically n < 30).\n",
        "\n",
        "Calculation: t = (x - μ) / (s / √n), where x is the data point, μ is the sample mean, s is the sample standard deviation, and n is the sample size."
      ],
      "metadata": {
        "id": "CnJg87NKA1_h"
      }
    }
  ]
}